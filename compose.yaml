version: '3.8'

services:
  app:
    build: .
    container_name: app
    ports:
      - 8000:8000
    networks:
      - surge_pricing_network
    environment:
      - REDIS_HOST=redis
      - PYTHONUNBUFFERED=1
    command: bash -c "/app/start_services.sh"
    depends_on:
      - kafka
    volumes:
      - .:/app  # Map the current directory to /app in the container

  cassandra:
    image: cassandra:5.0.2
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      CASSANDRA_CLUSTER_NAME: "Test Cluster"
      CASSANDRA_NUM_TOKENS: 256
      CASSANDRA_START_RPC: "true"
      CASSANDRA_LISTEN_ADDRESS: "127.0.0.1"  # Correct this to 0.0.0.0
      CASSANDRA_RPC_ADDRESS: "0.0.0.0"    # Keep this as 0.0.0.0
      CASSANDRA_BROADCAST_ADDRESS: "127.0.0.1"
    volumes:
      - cassandra_data_2:/var/lib/cassandra
    healthcheck:
      test: [ "CMD", "cqlsh", "-e", "DESCRIBE KEYSPACES" ]
      interval: 30s
      retries: 3
    networks:
      - surge_pricing_network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    container_name: zookeeper
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    ports:
      - "2181:2181"
    networks:
      - surge_pricing_network

  kafka:
    image: confluentinc/cp-kafka:5.5.1
    container_name: kafka5
    environment:
      - KAFKA_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP= PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_LISTENER_NAME=PLAINTEXT
      - KAFKA_LISTENER_PORT=9092
      - KAFKA_LISTENER_INTER_BROKER_PROTOCOL=PLAINTEXT
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    ports:
      - '9092:9092'
      - '29092:29092'
    depends_on:
      - zookeeper
    networks:
      - surge_pricing_network

  producer:
    build: .
    container_name: producer
    depends_on:
      - kafka
    networks:
      - surge_pricing_network
    environment:
      - DRIVER_POSITION_KAFKA_TOPIC=driver_position_stream
      - ORDERS_KAFKA_TOPIC=orders_stream
      - KAFKA_BROKER=kafka:29092
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
    command: bash -c "/app/start_kafka_producer.sh"
    volumes:
      - .:/app

#  logstash:
#    image: docker.elastic.co/logstash/logstash:8.10.1
#    container_name: logstash
#    ports:
#      - "5044:5044"
#      - "9600:9600"
#    volumes:
#      - ./logstash/pipeline:/usr/share/logstash/pipeline
#      - ./logstash/config:/usr/share/logstash/config
#    depends_on:
#      - elasticsearch
#    networks:
#      - surge_pricing_network

#  spark-master:
#    image: bitnami/spark:3.5.1
#    container_name: spark-master
#    hostname: spark-master
#    environment:
#      - SPARK_MODE=master
#      - SPARK_MASTER_HOST=spark-master
#      - SPARK_MASTER_PORT=7077
#      - DRIVER_POSITION_KAFKA_TOPIC=driver_position_stream
#      - ORDERS_KAFKA_TOPIC=orders_stream
#      - KAFKA_BROKER=kafka:29092
#      - REDIS_HOST=redis
#      - REDIS_PORT:6379
#    working_dir: /app
#    ports:
#      - "8080:8080"  # Spark Web UI
#      - "7077:7077"  # Spark Master Port
#    command: bash -c "/app/start_spark_master.sh"
#    volumes:
#      - .:/app
#    networks:
#      - surge_pricing_network
#    user: root
#
#  spark-worker:
#    image: bitnami/spark:3.5.1
#    container_name: spark-worker
#    hostname: spark-worker
#    environment:
#      - SPARK_MODE=worker
#      - SPARK_MASTER_URL=spark://spark-master:7077
#      - DRIVER_POSITION_KAFKA_TOPIC=driver_position_stream
#      - ORDERS_KAFKA_TOPIC=orders_stream
#      - KAFKA_BROKER=kafka:29092
#      - REDIS_HOST=redis
#      - REDIS_PORT:6379
#    command: bash -c "/app/start_spark_worker.sh"
#    volumes:
#      - .:/app
#    working_dir: /app
#    user: root
#    depends_on:
#      - spark-master
#    networks:
#      - surge_pricing_network

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - surge_pricing_network

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.17.1
    user: root
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs:/app/logs:ro
    command: filebeat -e
    networks:
      - surge_pricing_network

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.1
    environment: [ 'ES_JAVA_OPTS=-Xms2g -Xmx2g','bootstrap.memory_lock=true','discovery.type=single-node' ]
    ports:
      - 9200:9200
    networks:
      - surge_pricing_network
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data_elastic

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.1
    container_name: kibana
    environment:
      - "xpack.security.authc.http.enabled=false"
      - "XPACK_APM_SERVICEMAPENABLED=true"
      - "XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=d1a66dfd-c4d3-4a0a-8290-2abcb83ab3aa"
    ports:
      - 5601:5601
    networks:
      - surge_pricing_network

networks:
  surge_pricing_network:
    name: surge_pricing_network
    driver: bridge

volumes:
  cassandra_data_2:
  elasticsearch_data:
  app_logs:
